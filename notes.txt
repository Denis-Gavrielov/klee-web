References:

* src/klee_web/api/views.py
    from worker.worker import submit_code
        basically a POST request that will be translated to calling the
        submit_code function
    from worker.worker_config import WorkerConfig
        here only the timeout is needed -> so can get the timeout as an
        api GET.

* control_panel/klee_task.py
    from worker.worker import celery
        instance of celery -> replace this entirely with api GET calls.

* control_panel/views.py
    from worker.worker import celery
        additional stats that need to be exposed via GET
    from worker.worker_config import WorkerConfig
        should be able to do POST and GET, given that the WorkerConfig class
        just adapts the global redis queue
        
* tests/testcase_generate.py
    this will be tricky, need to think about how to rewrite the test.


imports overall:
* celery  -> could instantiate it separately in both places, or have a
  "common library"
* WorkerConfig
    this one is tricky because it is actually used in multiple places in
    both directories.
    * can use another celery task to query these values.
* submit_code -> can use signatures
    * http://docs.celeryproject.org/en/latest/userguide/canvas.html
    * https://stackoverflow.com/questions/36974580/how-can-i-use-celery-with-different-code-base-in-api-and-workers

so: either keep the export PYTHONPATH and just import the worker from src, or
  make the WorkerConfig also celery tasks, export the signatures (need to try)
  and instantiate celery in projects.